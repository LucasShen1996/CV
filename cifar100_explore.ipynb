{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yWWxferUHsw7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,BatchNormalization,LayerNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.python.data import Dataset, AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.6.0\n",
      "Use devices: ['/physical_device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.eager.context import PhysicalDevice\n",
    "from typing import List\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "# setting the growth GPU memory occupying and print devices\n",
    "try:\n",
    "    devices: List[PhysicalDevice] = tf.config.list_physical_devices('GPU')\n",
    "    for device in devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "    print(\"Use devices:\", list(map(lambda d: d.name, devices)))\n",
    "except IndexError:\n",
    "    print(\"Use CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8AOxOGzAIXFZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cifar100 = tf.keras.datasets.cifar100\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DxC5ncg6Ko-q",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pair_dataset = Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_dataset = Dataset.from_tensor_slices((test_images, test_labels))\n",
    "# zip images and labels as pairs\n",
    "\n",
    "# split the train and validation dataset\n",
    "val_size = int(len(train_images)* 0.2)\n",
    "train_dataset = pair_dataset.skip(val_size)\n",
    "val_dataset = pair_dataset.take(val_size)\n",
    "\n",
    "# define the batch_size and shuffle\n",
    "train_dataset = train_dataset.cache().shuffle(buffer_size=1000).batch(256).prefetch(AUTOTUNE)\n",
    "val_dataset = val_dataset.cache().batch(64).prefetch(AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().shuffle(buffer_size=1000).batch(256).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 1 Baseline CNN model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        2368      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 32)          12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 93,764\n",
      "Trainable params: 93,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Baseline_CNN_model = Sequential([\n",
    "    Conv2D(16,7,strides= 1,padding='valid', activation=\"relu\", input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D(2, strides=2),\n",
    "    Conv2D(32, 5,strides= 1,padding='valid', activation=\"relu\"),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dense(100),\n",
    "])\n",
    "\n",
    "# TODO - Print summary\n",
    "Baseline_CNN_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "lr_decay = ExponentialDecay(learning_rate, decay_steps=100, decay_rate=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVBtBTVAJ062",
    "outputId": "f7fc40a8-7b0c-410d-982b-7e07f41ec111",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 27s 7ms/step - loss: 5.6440 - accuracy: 0.0154 - val_loss: 4.4861 - val_accuracy: 0.0270\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.4249 - accuracy: 0.0345 - val_loss: 4.3756 - val_accuracy: 0.0384\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.3112 - accuracy: 0.0500 - val_loss: 4.3619 - val_accuracy: 0.0421\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.2281 - accuracy: 0.0655 - val_loss: 4.2033 - val_accuracy: 0.0666\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.1223 - accuracy: 0.0786 - val_loss: 4.1184 - val_accuracy: 0.0817\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 4.0135 - accuracy: 0.0942 - val_loss: 4.0447 - val_accuracy: 0.0875\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.9184 - accuracy: 0.1083 - val_loss: 3.9924 - val_accuracy: 0.0977\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.8405 - accuracy: 0.1199 - val_loss: 3.9256 - val_accuracy: 0.1083\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.7477 - accuracy: 0.1343 - val_loss: 3.8526 - val_accuracy: 0.1212\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.6761 - accuracy: 0.1482 - val_loss: 3.8209 - val_accuracy: 0.1261\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.6039 - accuracy: 0.1608 - val_loss: 3.8285 - val_accuracy: 0.1299\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.5522 - accuracy: 0.1709 - val_loss: 3.7753 - val_accuracy: 0.1377\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.4914 - accuracy: 0.1826 - val_loss: 3.7417 - val_accuracy: 0.1458\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.4419 - accuracy: 0.1931 - val_loss: 3.7275 - val_accuracy: 0.1500\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.3889 - accuracy: 0.2019 - val_loss: 3.6957 - val_accuracy: 0.1583\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.3506 - accuracy: 0.2072 - val_loss: 3.6862 - val_accuracy: 0.1588\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.3103 - accuracy: 0.2157 - val_loss: 3.6902 - val_accuracy: 0.1569\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.2652 - accuracy: 0.2255 - val_loss: 3.6529 - val_accuracy: 0.1648\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.2308 - accuracy: 0.2306 - val_loss: 3.6566 - val_accuracy: 0.1671\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.1909 - accuracy: 0.2399 - val_loss: 3.6440 - val_accuracy: 0.1713\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.1581 - accuracy: 0.2441 - val_loss: 3.6351 - val_accuracy: 0.1716\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.1234 - accuracy: 0.2537 - val_loss: 3.6286 - val_accuracy: 0.1728\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.0959 - accuracy: 0.2579 - val_loss: 3.6225 - val_accuracy: 0.1748\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.0702 - accuracy: 0.2636 - val_loss: 3.6239 - val_accuracy: 0.1771\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.0487 - accuracy: 0.2676 - val_loss: 3.6263 - val_accuracy: 0.1790\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.0224 - accuracy: 0.2717 - val_loss: 3.6069 - val_accuracy: 0.1856\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 3.0005 - accuracy: 0.2760 - val_loss: 3.6101 - val_accuracy: 0.1870\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.9754 - accuracy: 0.2811 - val_loss: 3.6134 - val_accuracy: 0.1867\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.9575 - accuracy: 0.2856 - val_loss: 3.6118 - val_accuracy: 0.1849\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.9441 - accuracy: 0.2887 - val_loss: 3.6073 - val_accuracy: 0.1893\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.9234 - accuracy: 0.2920 - val_loss: 3.6081 - val_accuracy: 0.1906\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.9070 - accuracy: 0.2956 - val_loss: 3.6216 - val_accuracy: 0.1911\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.8919 - accuracy: 0.2988 - val_loss: 3.6199 - val_accuracy: 0.1896\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.8768 - accuracy: 0.3009 - val_loss: 3.6274 - val_accuracy: 0.1896\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.8619 - accuracy: 0.3054 - val_loss: 3.6250 - val_accuracy: 0.1910\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.8529 - accuracy: 0.3072 - val_loss: 3.6281 - val_accuracy: 0.1907\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.8407 - accuracy: 0.3098 - val_loss: 3.6324 - val_accuracy: 0.1909\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.8263 - accuracy: 0.3126 - val_loss: 3.6341 - val_accuracy: 0.1917\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.8169 - accuracy: 0.3138 - val_loss: 3.6387 - val_accuracy: 0.1920\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.8088 - accuracy: 0.3165 - val_loss: 3.6366 - val_accuracy: 0.1918\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.7961 - accuracy: 0.3181 - val_loss: 3.6421 - val_accuracy: 0.1935\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.7875 - accuracy: 0.3209 - val_loss: 3.6358 - val_accuracy: 0.1940\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.7793 - accuracy: 0.3231 - val_loss: 3.6391 - val_accuracy: 0.1932\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.7733 - accuracy: 0.3235 - val_loss: 3.6385 - val_accuracy: 0.1946\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.7638 - accuracy: 0.3263 - val_loss: 3.6391 - val_accuracy: 0.1945\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.7572 - accuracy: 0.3274 - val_loss: 3.6409 - val_accuracy: 0.1947\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.7495 - accuracy: 0.3292 - val_loss: 3.6395 - val_accuracy: 0.1944\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.7439 - accuracy: 0.3309 - val_loss: 3.6388 - val_accuracy: 0.1956\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.7381 - accuracy: 0.3326 - val_loss: 3.6406 - val_accuracy: 0.1951\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.7330 - accuracy: 0.3336 - val_loss: 3.6413 - val_accuracy: 0.1973\n"
     ]
    }
   ],
   "source": [
    "Baseline_CNN_model.compile(optimizer=Adam(lr_decay),\n",
    "                  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[\"accuracy\"])\n",
    "history = Baseline_CNN_model.fit(train_dataset, validation_data=val_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AWXUqKUUMxya",
    "outputId": "64ee5e0a-19ae-4b8f-ecad-5db5d71b09a2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 3.6444 - accuracy: 0.1958\n",
      "Accuracy: 0.19580000638961792\n"
     ]
    }
   ],
   "source": [
    "loss, acc = Baseline_CNN_model.evaluate(test_dataset)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 2 Best model\n",
    "\n",
    "Using Rescaling, Data Normalization, Data augmentation ,Batch Normalizationand,layer normalization and ResNet18 model to get best accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "I69nCDRwXiJa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling,RandomFlip, RandomRotation, RandomZoom\n",
    "data_preprocess = Sequential([\n",
    "  Rescaling(1 / 255,input_shape=(32,32,3)),\n",
    "  RandomFlip(\"horizontal_and_vertical\"),\n",
    "  RandomRotation(0.2),\n",
    "  RandomZoom(0.1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_net18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_1 (Rescaling)      (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 32, 32, 3)         7         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, 16, 16, 64)        128       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "residual_block (ResidualBloc (None, 8, 8, 64)          153408    \n",
      "_________________________________________________________________\n",
      "residual_block_1 (ResidualBl (None, 4, 4, 128)         528000    \n",
      "_________________________________________________________________\n",
      "residual_block_2 (ResidualBl (None, 2, 2, 256)         2104576   \n",
      "_________________________________________________________________\n",
      "residual_block_3 (ResidualBl (None, 1, 1, 512)         8403456   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               51300     \n",
      "=================================================================\n",
      "Total params: 11,250,603\n",
      "Trainable params: 11,242,788\n",
      "Non-trainable params: 7,815\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO - Define ResNet18 model.\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, BatchNormalization, ReLU, Add, GlobalAvgPool2D, Input,LayerNormalization\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class ResidualBlockType(Enum):\n",
    "    SHALLOW = \"shallow\"  # the block used in ResNet18 and ResNet34\n",
    "    DEEP = \"deep\"  # the block used in ResNet50, ResNet101 and ResNet152\n",
    "\n",
    "\n",
    "class ResidualBlock(Layer):\n",
    "    class ShallowPath(Layer):\n",
    "        def __init__(self, filters: int, strides: int):\n",
    "            super().__init__()\n",
    "            self.conv0 = Conv2D(filters, kernel_size=3, padding=\"same\", strides=strides)\n",
    "            self.bn0 = BatchNormalization()\n",
    "            self.relu0 = ReLU()\n",
    "            self.layer_norm0 = LayerNormalization(axis=3 , center=True , scale=True)\n",
    "            self.conv1 = Conv2D(filters, kernel_size=3, padding=\"same\")\n",
    "            self.bn1 = BatchNormalization()\n",
    "            self.layer_norm1 = LayerNormalization(axis=3 , center=True , scale=True)\n",
    "        def call(self, inputs, *args, **kwargs):\n",
    "            x = self.conv0(inputs)\n",
    "            x = self.layer_norm0(x)\n",
    "            x = self.bn0(x)\n",
    "            x = self.relu0(x)\n",
    "\n",
    "            x = self.conv1(x)\n",
    "            x = self.layer_norm1(x)\n",
    "            x = self.bn1(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    class DeepPath(Layer):\n",
    "        def __init__(self, filters: int, strides: int):\n",
    "            super().__init__()\n",
    "            self.conv0 = Conv2D(filters, kernel_size=1, padding=\"same\", strides=strides)\n",
    "            self.bn0 = BatchNormalization()\n",
    "            self.layer_norm0 = LayerNormalization(axis=3 , center=True , scale=True)\n",
    "            self.relu0 = ReLU()\n",
    "\n",
    "            self.conv1 = Conv2D(filters, kernel_size=3, padding=\"same\")\n",
    "            self.bn1 = BatchNormalization()\n",
    "            self.layer_norm1 = LayerNormalization(axis=3 , center=True , scale=True)\n",
    "            self.relu1 = ReLU()\n",
    "\n",
    "            self.conv2 = Conv2D(filters * 4, kernel_size=1, padding=\"same\")\n",
    "            self.bn2 = BatchNormalization()\n",
    "            self.layer_norm2 = LayerNormalization(axis=3 , center=True , scale=True)\n",
    "\n",
    "        def call(self, inputs, *args, **kwargs):\n",
    "            x = self.conv0(inputs)\n",
    "            x = self.layer_norm0(x)\n",
    "            x = self.bn0(x)\n",
    "            x = self.relu0(x)\n",
    "\n",
    "            x = self.conv1(x)\n",
    "            x = self.layer_norm1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu1(x)\n",
    "\n",
    "            x = self.conv2(x)\n",
    "            x = self.layer_norm2(x)\n",
    "            x = self.bn2(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    def __init__(self, filters: int, strides: int, repeat: int,\n",
    "                 architecture: ResidualBlockType = ResidualBlockType.SHALLOW):\n",
    "        super().__init__()\n",
    "        if architecture == ResidualBlockType.SHALLOW:\n",
    "            MainPath = ResidualBlock.ShallowPath\n",
    "        elif architecture == ResidualBlockType.DEEP:\n",
    "            MainPath = ResidualBlock.DeepPath\n",
    "        else:\n",
    "            raise ValueError(\"Unknown residual block type\")\n",
    "\n",
    "        self.repeat = repeat\n",
    "        self.blocks = []\n",
    "        for i in range(repeat):\n",
    "            main_path = MainPath(filters, strides=strides) if i == 0 else MainPath(filters, 1)\n",
    "            residual_path = Conv2D(filters, kernel_size=1,\n",
    "                                   strides=strides) if i == 0 else Layer()  # Layer class used here as Identity layer\n",
    "            addition = Add()\n",
    "            relu = ReLU()\n",
    "            self.blocks.append((main_path, residual_path, addition, relu))\n",
    "\n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        x = inputs\n",
    "        for i in range(self.repeat):\n",
    "            main_path, residual_path, addition, relu = self.blocks[i]\n",
    "            main_path_x = main_path(x)\n",
    "            residual_path_x = residual_path(x)\n",
    "            x = addition([main_path_x, residual_path_x])\n",
    "            x = relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet18(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rescaling = tf.keras.layers.Rescaling(1/255)\n",
    "        self.norm_data = tf.keras.layers.Normalization()\n",
    "        self.conv1 = Conv2D(64, 7, strides=2, padding=\"same\")\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.layer_norm = LayerNormalization(axis=3 , center=True , scale=True)\n",
    "        self.relu1 = ReLU()\n",
    "        self.pool1 = MaxPooling2D(3, strides=2, padding=\"same\")\n",
    "\n",
    "        residual_type = ResidualBlockType.SHALLOW\n",
    "\n",
    "        self.conv2_x = ResidualBlock(filters=64, strides=1, repeat=2, architecture=residual_type)\n",
    "        self.conv3_x = ResidualBlock(filters=128, strides=2, repeat=2, architecture=residual_type)\n",
    "        self.conv4_x = ResidualBlock(filters=256, strides=2, repeat=2, architecture=residual_type)\n",
    "        self.conv5_x = ResidualBlock(filters=512, strides=2, repeat=2, architecture=residual_type)\n",
    "\n",
    "        self.global_pool = GlobalAvgPool2D()\n",
    "        self.fc = Dense(100)\n",
    "\n",
    "        self.build(input_shape=(None, 32, 32, 3))\n",
    "        self.call(Input(shape=(32, 32, 3)))\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.rescaling(inputs)\n",
    "        x = self.norm_data(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2_x(x)\n",
    "        x = self.conv3_x(x)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        pass\n",
    "best_model = ResNet18()\n",
    "best_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 13s 66ms/step - loss: 1.8567 - accuracy: 0.4904 - val_loss: 3.0054 - val_accuracy: 0.2841\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 1.5424 - accuracy: 0.5664 - val_loss: 3.3696 - val_accuracy: 0.2568\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 1.2960 - accuracy: 0.6244 - val_loss: 3.1897 - val_accuracy: 0.2990\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 1.0613 - accuracy: 0.6891 - val_loss: 3.2840 - val_accuracy: 0.3032\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 0.8483 - accuracy: 0.7473 - val_loss: 3.7727 - val_accuracy: 0.2745\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 0.6508 - accuracy: 0.8058 - val_loss: 3.6311 - val_accuracy: 0.2955\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.5172 - accuracy: 0.8434 - val_loss: 3.8138 - val_accuracy: 0.3062\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.3896 - accuracy: 0.8827 - val_loss: 4.1733 - val_accuracy: 0.2908\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.2898 - accuracy: 0.9158 - val_loss: 3.8536 - val_accuracy: 0.3260\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.2201 - accuracy: 0.9369 - val_loss: 4.2637 - val_accuracy: 0.3110\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.1686 - accuracy: 0.9528 - val_loss: 3.8350 - val_accuracy: 0.3661\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.1291 - accuracy: 0.9658 - val_loss: 3.9661 - val_accuracy: 0.3534\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0975 - accuracy: 0.9754 - val_loss: 4.0783 - val_accuracy: 0.3552\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0716 - accuracy: 0.9837 - val_loss: 3.8897 - val_accuracy: 0.3819\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0531 - accuracy: 0.9883 - val_loss: 3.9748 - val_accuracy: 0.3839\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0362 - accuracy: 0.9935 - val_loss: 3.8957 - val_accuracy: 0.3938\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0278 - accuracy: 0.9954 - val_loss: 3.9581 - val_accuracy: 0.3999\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0204 - accuracy: 0.9969 - val_loss: 4.0869 - val_accuracy: 0.3949\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0158 - accuracy: 0.9981 - val_loss: 3.9336 - val_accuracy: 0.4101\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0127 - accuracy: 0.9986 - val_loss: 3.9982 - val_accuracy: 0.4053\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0091 - accuracy: 0.9991 - val_loss: 3.9535 - val_accuracy: 0.4135\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 3.8788 - val_accuracy: 0.4216\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 3.8801 - val_accuracy: 0.4259\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 3.8951 - val_accuracy: 0.4269\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 3.9497 - val_accuracy: 0.4238\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 3.8941 - val_accuracy: 0.4308\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 3.9037 - val_accuracy: 0.4327\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 3.9187 - val_accuracy: 0.4323\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 3.9159 - val_accuracy: 0.4342\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 3.9286 - val_accuracy: 0.4321\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 10s 63ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 3.9452 - val_accuracy: 0.4316\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 3.9567 - val_accuracy: 0.4308\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 3.9563 - val_accuracy: 0.4327\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 3.9751 - val_accuracy: 0.4325\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 3.9818 - val_accuracy: 0.4329\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 3.9943 - val_accuracy: 0.4330\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 3.9951 - val_accuracy: 0.4327\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 4.0115 - val_accuracy: 0.4315\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 4.0114 - val_accuracy: 0.4346\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 4.0281 - val_accuracy: 0.4348\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 4.0380 - val_accuracy: 0.4330\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 4.0506 - val_accuracy: 0.4314\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 10s 63ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 4.0447 - val_accuracy: 0.4350\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 4.0475 - val_accuracy: 0.4353\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 4.0512 - val_accuracy: 0.4356\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 4.0624 - val_accuracy: 0.4353\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 4.0719 - val_accuracy: 0.4350\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 4.0746 - val_accuracy: 0.4339\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 4.0774 - val_accuracy: 0.4344\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 4.1247 - val_accuracy: 0.4318\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 4.1668 - accuracy: 0.4338\n",
      "Accuracy: 0.43380001187324524\n"
     ]
    }
   ],
   "source": [
    "best_model.compile(optimizer=Adam(lr_decay),\n",
    "                  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[\"accuracy\"])\n",
    "epochs = 50\n",
    "history_18 = best_model.fit(train_dataset, validation_data=val_dataset, epochs=epochs)\n",
    "loss_1, acc_1 = best_model.evaluate(test_dataset)\n",
    "print(\"Accuracy:\", acc_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 3\n",
    "add attention layer to the resNet18"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.16.1-cp38-cp38-win_amd64.whl (755 kB)\n",
      "     -------------------------------------- 755.7/755.7 KB 6.8 MB/s eta 0:00:00\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.16.1 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_net18_attention_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_3 (Rescaling)      (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "normalization_2 (Normalizati (None, 32, 32, 3)         7         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 16, 16, 64)        9472      \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 8, 8, 64)          200768    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "layer_normalization_34 (Laye (None, 16, 16, 64)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_34 (ReLU)              (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "residual_block_8 (ResidualBl (None, 8, 8, 64)          153408    \n",
      "_________________________________________________________________\n",
      "residual_block_9 (ResidualBl (None, 4, 4, 128)         528000    \n",
      "_________________________________________________________________\n",
      "residual_block_10 (ResidualB (None, 2, 2, 256)         2104576   \n",
      "_________________________________________________________________\n",
      "residual_block_11 (ResidualB (None, 1, 1, 512)         8403456   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               51300     \n",
      "=================================================================\n",
      "Total params: 11,451,371\n",
      "Trainable params: 11,443,556\n",
      "Non-trainable params: 7,815\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO - Define ResNet18 model.\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, BatchNormalization, ReLU, Add, GlobalAvgPool2D, Input,LayerNormalization,Attention,Softmax\n",
    "# from tensorflow.keras.layers import Attention,Reshape,Input,Conv2D,Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class ResidualBlockType(Enum):\n",
    "    SHALLOW = \"shallow\"  # the block used in ResNet18 and ResNet34\n",
    "    DEEP = \"deep\"  # the block used in ResNet50, ResNet101 and ResNet152\n",
    "\n",
    "\n",
    "class ResidualBlock(Layer):\n",
    "    class ShallowPath(Layer):\n",
    "        def __init__(self, filters: int, strides: int):\n",
    "            super().__init__()\n",
    "            self.conv0 = Conv2D(filters, kernel_size=3, padding=\"same\", strides=strides)\n",
    "            self.bn0 = BatchNormalization()\n",
    "            self.relu0 = ReLU()\n",
    "            self.layer_norm0 = LayerNormalization(axis=3 , center=True , scale=True)\n",
    "            self.conv1 = Conv2D(filters, kernel_size=3, padding=\"same\")\n",
    "            self.bn1 = BatchNormalization()\n",
    "            self.layer_norm1 = LayerNormalization(axis=3 , center=True , scale=True)\n",
    "        def call(self, inputs, *args, **kwargs):\n",
    "            x = self.conv0(inputs)\n",
    "            x = self.layer_norm0(x)\n",
    "            x = self.bn0(x)\n",
    "            x = self.relu0(x)\n",
    "\n",
    "            x = self.conv1(x)\n",
    "            x = self.layer_norm1(x)\n",
    "            x = self.bn1(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    class DeepPath(Layer):\n",
    "        def __init__(self, filters: int, strides: int):\n",
    "            super().__init__()\n",
    "            self.conv0 = Conv2D(filters, kernel_size=1, padding=\"same\", strides=strides)\n",
    "            self.bn0 = BatchNormalization()\n",
    "            self.layer_norm0 = LayerNormalization(axis=3 , center=True , scale=True)\n",
    "            self.relu0 = ReLU()\n",
    "\n",
    "            self.conv1 = Conv2D(filters, kernel_size=3, padding=\"same\")\n",
    "            self.bn1 = BatchNormalization()\n",
    "            self.layer_norm1 = LayerNormalization(axis=3 , center=True , scale=True)\n",
    "            self.relu1 = ReLU()\n",
    "\n",
    "            self.conv2 = Conv2D(filters * 4, kernel_size=1, padding=\"same\")\n",
    "            self.bn2 = BatchNormalization()\n",
    "            self.layer_norm2 = LayerNormalization(axis=3 , center=True , scale=True)\n",
    "\n",
    "        def call(self, inputs, *args, **kwargs):\n",
    "            x = self.conv0(inputs)\n",
    "            x = self.layer_norm0(x)\n",
    "            x = self.bn0(x)\n",
    "            x = self.relu0(x)\n",
    "\n",
    "            x = self.conv1(x)\n",
    "            x = self.layer_norm1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu1(x)\n",
    "\n",
    "            x = self.conv2(x)\n",
    "            x = self.layer_norm2(x)\n",
    "            x = self.bn2(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    def __init__(self, filters: int, strides: int, repeat: int,\n",
    "                 architecture: ResidualBlockType = ResidualBlockType.SHALLOW):\n",
    "        super().__init__()\n",
    "        if architecture == ResidualBlockType.SHALLOW:\n",
    "            MainPath = ResidualBlock.ShallowPath\n",
    "        elif architecture == ResidualBlockType.DEEP:\n",
    "            MainPath = ResidualBlock.DeepPath\n",
    "        else:\n",
    "            raise ValueError(\"Unknown residual block type\")\n",
    "\n",
    "        self.repeat = repeat\n",
    "        self.blocks = []\n",
    "        for i in range(repeat):\n",
    "            main_path = MainPath(filters, strides=strides) if i == 0 else MainPath(filters, 1)\n",
    "            residual_path = Conv2D(filters, kernel_size=1,\n",
    "                                   strides=strides) if i == 0 else Layer()  # Layer class used here as Identity layer\n",
    "            addition = Add()\n",
    "            relu = ReLU()\n",
    "            self.blocks.append((main_path, residual_path, addition, relu))\n",
    "\n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        x = inputs\n",
    "        for i in range(self.repeat):\n",
    "            main_path, residual_path, addition, relu = self.blocks[i]\n",
    "            main_path_x = main_path(x)\n",
    "            residual_path_x = residual_path(x)\n",
    "            x = addition([main_path_x, residual_path_x])\n",
    "            x = relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet18_attention(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rescaling = tf.keras.layers.Rescaling(1/255)\n",
    "        self.norm_data = tf.keras.layers.Normalization()\n",
    "        self.conv1 = Conv2D(64, 7, strides=2, padding=\"same\")\n",
    "        self.attention = Sequential([Conv2D(64,7, strides=2, padding=\"same\"),tfa.layers.AdaptiveAveragePooling2D((8,8)),Softmax()])\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.layer_norm = LayerNormalization(axis=3 , center=True , scale=True)\n",
    "        self.relu1 = ReLU()\n",
    "        self.pool1 = MaxPooling2D(3, strides=2, padding=\"same\")\n",
    "\n",
    "        residual_type = ResidualBlockType.SHALLOW\n",
    "\n",
    "        self.conv2_x = ResidualBlock(filters=64, strides=1, repeat=2, architecture=residual_type)\n",
    "        self.conv3_x = ResidualBlock(filters=128, strides=2, repeat=2, architecture=residual_type)\n",
    "        self.conv4_x = ResidualBlock(filters=256, strides=2, repeat=2, architecture=residual_type)\n",
    "        self.conv5_x = ResidualBlock(filters=512, strides=2, repeat=2, architecture=residual_type)\n",
    "\n",
    "        self.global_pool = GlobalAvgPool2D()\n",
    "        self.fc = Dense(100)\n",
    "\n",
    "        self.build(input_shape=(None, 32, 32, 3))\n",
    "        self.call(Input(shape=(32, 32, 3)))\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.rescaling(inputs)\n",
    "        x = self.norm_data(x)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x_attention =  self.attention(x)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = x*x_attention\n",
    "        x = self.conv2_x(x)\n",
    "\n",
    "        x = self.conv3_x(x)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        pass\n",
    "task_3 = ResNet18_attention()\n",
    "task_3 .summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 15s 75ms/step - loss: 3.7093 - accuracy: 0.1499 - val_loss: 4.4633 - val_accuracy: 0.0471\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 3.0237 - accuracy: 0.2503 - val_loss: 3.9909 - val_accuracy: 0.1008\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 2.6428 - accuracy: 0.3214 - val_loss: 3.2032 - val_accuracy: 0.2252\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 2.3446 - accuracy: 0.3830 - val_loss: 3.8718 - val_accuracy: 0.1800\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 2.1012 - accuracy: 0.4336 - val_loss: 3.8378 - val_accuracy: 0.1937\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 1.8710 - accuracy: 0.4853 - val_loss: 3.5909 - val_accuracy: 0.2142\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 1.6458 - accuracy: 0.5391 - val_loss: 3.5619 - val_accuracy: 0.2425\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 1.4234 - accuracy: 0.5942 - val_loss: 3.6839 - val_accuracy: 0.2436\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 1.2144 - accuracy: 0.6515 - val_loss: 3.9386 - val_accuracy: 0.2147\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 1.0092 - accuracy: 0.7035 - val_loss: 3.7093 - val_accuracy: 0.2616\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 0.8073 - accuracy: 0.7635 - val_loss: 4.1186 - val_accuracy: 0.2341\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.6526 - accuracy: 0.8073 - val_loss: 3.6341 - val_accuracy: 0.2955\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.5028 - accuracy: 0.8527 - val_loss: 4.0787 - val_accuracy: 0.2742\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 0.3779 - accuracy: 0.8910 - val_loss: 3.9849 - val_accuracy: 0.2942\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.2827 - accuracy: 0.9220 - val_loss: 4.0473 - val_accuracy: 0.3040\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 0.2101 - accuracy: 0.9440 - val_loss: 3.7950 - val_accuracy: 0.3431\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 0.1511 - accuracy: 0.9628 - val_loss: 3.9525 - val_accuracy: 0.3356\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 0.1116 - accuracy: 0.9757 - val_loss: 4.0369 - val_accuracy: 0.3415\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0786 - accuracy: 0.9839 - val_loss: 3.9999 - val_accuracy: 0.3500\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 0.0546 - accuracy: 0.9909 - val_loss: 4.0695 - val_accuracy: 0.3482\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0401 - accuracy: 0.9942 - val_loss: 3.9617 - val_accuracy: 0.3685\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0304 - accuracy: 0.9962 - val_loss: 3.9526 - val_accuracy: 0.3776\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0222 - accuracy: 0.9978 - val_loss: 4.0386 - val_accuracy: 0.3711\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0174 - accuracy: 0.9985 - val_loss: 4.0194 - val_accuracy: 0.3812\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0133 - accuracy: 0.9992 - val_loss: 3.9901 - val_accuracy: 0.3879\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0113 - accuracy: 0.9990 - val_loss: 3.8994 - val_accuracy: 0.4002\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0100 - accuracy: 0.9990 - val_loss: 3.9086 - val_accuracy: 0.4030\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 3.9137 - val_accuracy: 0.4075\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 3.9450 - val_accuracy: 0.4051\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 3.9542 - val_accuracy: 0.4080\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 3.9648 - val_accuracy: 0.4085\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 3.9965 - val_accuracy: 0.4059\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 3.9816 - val_accuracy: 0.4120\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 4.0222 - val_accuracy: 0.4024\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 4.0213 - val_accuracy: 0.4119\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 4.0376 - val_accuracy: 0.4063\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 4.0732 - val_accuracy: 0.4016\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 11s 72ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 4.0335 - val_accuracy: 0.4090\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 4.0334 - val_accuracy: 0.4076\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 4.0551 - val_accuracy: 0.4077\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 4.0593 - val_accuracy: 0.4068\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 4.0671 - val_accuracy: 0.4082\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 4.0751 - val_accuracy: 0.4078\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 4.0815 - val_accuracy: 0.4079\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 4.0917 - val_accuracy: 0.4075\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 4.0983 - val_accuracy: 0.4096\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 4.1015 - val_accuracy: 0.4094\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 4.1150 - val_accuracy: 0.4106\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 4.1277 - val_accuracy: 0.4094\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 11s 71ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 4.1329 - val_accuracy: 0.4108\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 4.1291 - accuracy: 0.4128\n",
      "Accuracy: 0.41280001401901245\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "lr_decay = ExponentialDecay(learning_rate, decay_steps=100, decay_rate=0.96)\n",
    "task_3.compile(optimizer=Adam(lr_decay),\n",
    "                  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[\"accuracy\"])\n",
    "epochs = 50\n",
    "history_18 = task_3.fit(train_dataset, validation_data=val_dataset, epochs=epochs)\n",
    "loss_1, acc_1 = task_3.evaluate(test_dataset)\n",
    "print(\"Accuracy:\", acc_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
